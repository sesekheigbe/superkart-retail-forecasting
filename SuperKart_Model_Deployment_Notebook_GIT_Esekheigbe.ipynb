{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sesekheigbe/superkart-retail-forecasting/blob/main/SuperKart_Model_Deployment_Notebook_GIT_Esekheigbe.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "k-xVqOB6QTm6",
      "metadata": {
        "id": "k-xVqOB6QTm6"
      },
      "source": [
        "# **Problem Statement**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "AJDbTeirQasg",
      "metadata": {
        "id": "AJDbTeirQasg"
      },
      "source": [
        "## Business Context"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "94bMSnpWQmuA",
      "metadata": {
        "id": "94bMSnpWQmuA"
      },
      "source": [
        "A sales forecast is a prediction of future sales revenue based on historical data, industry trends, and the status of the current sales pipeline. Businesses use the sales forecast to estimate weekly, monthly, quarterly, and annual sales totals. A company needs to make an accurate sales forecast as it adds value across an organization and helps the different verticals to chalk out their future course of action.\n",
        "\n",
        "Forecasting helps an organization plan its sales operations by region and provides valuable insights to the supply chain team regarding the procurement of goods and materials. An accurate sales forecast process has many benefits which include improved decision-making about the future and reduction of sales pipeline and forecast risks. Moreover, it helps to reduce the time spent in planning territory coverage and establish benchmarks that can be used to assess trends in the future."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Aasy7LC_Qpq5",
      "metadata": {
        "id": "Aasy7LC_Qpq5"
      },
      "source": [
        "## Objective"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "khshBslaQtX9",
      "metadata": {
        "id": "khshBslaQtX9"
      },
      "source": [
        "SuperKart is a retail chain operating supermarkets and food marts across various tier cities, offering a wide range of products. To optimize its inventory management and make informed decisions around regional sales strategies, SuperKart wants to accurately forecast the sales revenue of its outlets for the upcoming quarter.\n",
        "\n",
        "To operationalize these insights at scale, the company has partnered with a data science firm—not just to build a predictive model based on historical sales data, but to develop and deploy a robust forecasting solution that can be integrated into SuperKart’s decision-making systems and used across its network of stores."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "v-HxlIhTQ0-E",
      "metadata": {
        "id": "v-HxlIhTQ0-E"
      },
      "source": [
        "## Data Description"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c0670116",
      "metadata": {
        "id": "c0670116"
      },
      "source": [
        "The data contains the different attributes of the various products and stores.The detailed data dictionary is given below.\n",
        "\n",
        "- **Product_Id** - unique identifier of each product, each identifier having two letters at the beginning followed by a number.\n",
        "- **Product_Weight** - weight of each product\n",
        "- **Product_Sugar_Content** - sugar content of each product like low sugar, regular and no sugar\n",
        "- **Product_Allocated_Area** - ratio of the allocated display area of each product to the total display area of all the products in a store\n",
        "- **Product_Type** - broad category for each product like meat, snack foods, hard drinks, dairy, canned, soft drinks, health and hygiene, baking goods, bread, breakfast, frozen foods, fruits and vegetables, household, seafood, starchy foods, others\n",
        "- **Product_MRP** - maximum retail price of each product\n",
        "- **Store_Id** - unique identifier of each store\n",
        "- **Store_Establishment_Year** - year in which the store was established\n",
        "- **Store_Size** - size of the store depending on sq. feet like high, medium and low\n",
        "- **Store_Location_City_Type** - type of city in which the store is located like Tier 1, Tier 2 and Tier 3. Tier 1 consists of cities where the standard of living is comparatively higher than its Tier 2 and Tier 3 counterparts.\n",
        "- **Store_Type** - type of store depending on the products that are being sold there like Departmental Store, Supermarket Type 1, Supermarket Type 2 and Food Mart\n",
        "- **Product_Store_Sales_Total** - total revenue generated by the sale of that particular product in that particular store\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "60VhOlydQ-PG",
      "metadata": {
        "id": "60VhOlydQ-PG"
      },
      "source": [
        "# **Installing and Importing the necessary libraries**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "yisDjKOB6TqF",
      "metadata": {
        "id": "yisDjKOB6TqF"
      },
      "outputs": [],
      "source": [
        "#Installing the libraries with the specified versions\n",
        "!pip install numpy==2.0.2 pandas==2.2.2 scikit-learn==1.6.1 matplotlib==3.10.0 seaborn==0.13.2 joblib==1.4.2 xgboost==2.1.4 requests==2.32.3 huggingface_hub==0.30.1 streamlit==1.45.0 -q"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "m-wZg1XZ6bLa",
      "metadata": {
        "id": "m-wZg1XZ6bLa"
      },
      "source": [
        "**Note:**\n",
        "\n",
        "- After running the above cell, kindly restart the notebook kernel (for Jupyter Notebook) or runtime (for Google Colab) and run all cells sequentially from the next cell.\n",
        "\n",
        "- On executing the above line of code, you might see a warning regarding package dependencies. This error message can be ignored as the above code ensures that all necessary libraries and their dependencies are maintained to successfully execute the code in this notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c0022e4d",
      "metadata": {
        "id": "c0022e4d"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# Libraries to help with reading and manipulating data\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# For splitting the dataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Libaries to help with data visualization\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Removes the limit for the number of displayed columns\n",
        "pd.set_option(\"display.max_columns\", None)\n",
        "# Sets the limit for the number of displayed rows\n",
        "pd.set_option(\"display.max_rows\", 100)\n",
        "\n",
        "\n",
        "# Libraries different ensemble classifiers\n",
        "from sklearn.ensemble import (\n",
        "    BaggingRegressor,\n",
        "    RandomForestRegressor,\n",
        "    AdaBoostRegressor,\n",
        "    GradientBoostingRegressor,\n",
        ")\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "\n",
        "# Libraries to get different metric scores\n",
        "from sklearn.metrics import (\n",
        "    confusion_matrix,\n",
        "    accuracy_score,\n",
        "    precision_score,\n",
        "    recall_score,\n",
        "    f1_score,\n",
        "    mean_squared_error,\n",
        "    mean_absolute_error,\n",
        "    r2_score,\n",
        "    mean_absolute_percentage_error\n",
        ")\n",
        "\n",
        "# To create the pipeline\n",
        "from sklearn.compose import make_column_transformer\n",
        "from sklearn.pipeline import make_pipeline,Pipeline\n",
        "\n",
        "# To tune different models and standardize\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler,OneHotEncoder\n",
        "\n",
        "# To serialize the model\n",
        "import joblib\n",
        "\n",
        "# os related functionalities\n",
        "import os\n",
        "\n",
        "# API request\n",
        "import requests\n",
        "\n",
        "# for hugging face space authentication to upload files\n",
        "from huggingface_hub import login, HfApi"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "51b91836",
      "metadata": {
        "id": "51b91836"
      },
      "source": [
        "# **Loading the dataset**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "YckcdzTlp839"
      },
      "id": "YckcdzTlp839",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Read data\n",
        "kart = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/SuperKart/SuperKart.csv\")"
      ],
      "metadata": {
        "id": "WIbbw_QlfQq6"
      },
      "id": "WIbbw_QlfQq6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# copying data to another variable to avoid compromising original data\n",
        "data = kart.copy()"
      ],
      "metadata": {
        "id": "lzHZnGP6gb7B"
      },
      "id": "lzHZnGP6gb7B",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "W2sXwrUERYua",
      "metadata": {
        "id": "W2sXwrUERYua"
      },
      "source": [
        "# **Data Overview**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "View the first and last 5 rows of the dataset."
      ],
      "metadata": {
        "id": "kkScxdsuhGk4"
      },
      "id": "kkScxdsuhGk4"
    },
    {
      "cell_type": "code",
      "source": [
        "# First five rows of dataset\n",
        "data.head()"
      ],
      "metadata": {
        "id": "rtomleOyp8dQ"
      },
      "id": "rtomleOyp8dQ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Last five rows of dataset\n",
        "data.tail()"
      ],
      "metadata": {
        "id": "st7CbsYwhC4m"
      },
      "id": "st7CbsYwhC4m",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Shape of the dataset"
      ],
      "metadata": {
        "id": "qLkhP7ujGRpq"
      },
      "id": "qLkhP7ujGRpq"
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"There are {data.shape[0]} rows and {data.shape[1]} columns.\")"
      ],
      "metadata": {
        "id": "O-ReLpEzGb1U"
      },
      "id": "O-ReLpEzGb1U",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check the data types of the columns for the dataset"
      ],
      "metadata": {
        "id": "RplejykRG8J9"
      },
      "id": "RplejykRG8J9"
    },
    {
      "cell_type": "code",
      "source": [
        "data.info()"
      ],
      "metadata": {
        "id": "u_D5_p8xHDvE"
      },
      "id": "u_D5_p8xHDvE",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Statistical summary of the data"
      ],
      "metadata": {
        "id": "lt1R1MpWHNmF"
      },
      "id": "lt1R1MpWHNmF"
    },
    {
      "cell_type": "code",
      "source": [
        "data.describe(include=\"all\").T # see the difference in output compared to previous code without \"include all\""
      ],
      "metadata": {
        "id": "tUEBkdBLHbZe"
      },
      "id": "tUEBkdBLHbZe",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Checking for duplicate values"
      ],
      "metadata": {
        "id": "1o46nJObHx9k"
      },
      "id": "1o46nJObHx9k"
    },
    {
      "cell_type": "code",
      "source": [
        "data.duplicated().sum()"
      ],
      "metadata": {
        "id": "pCrZoyyRH4Vs"
      },
      "id": "pCrZoyyRH4Vs",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "checking for missing values"
      ],
      "metadata": {
        "id": "KZ4Uth4nICM-"
      },
      "id": "KZ4Uth4nICM-"
    },
    {
      "cell_type": "code",
      "source": [
        "data.isnull().sum()"
      ],
      "metadata": {
        "id": "ZAWRk_D5IFgL"
      },
      "id": "ZAWRk_D5IFgL",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "4oamAwxrVHLq",
      "metadata": {
        "id": "4oamAwxrVHLq"
      },
      "source": [
        "# **Exploratory Data Analysis (EDA)**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Univariate Analysis"
      ],
      "metadata": {
        "id": "y1gvMTV9qCa1"
      },
      "id": "y1gvMTV9qCa1"
    },
    {
      "cell_type": "code",
      "source": [
        "# function to plot a boxplot and a histogram along the same scale.\n",
        "\n",
        "def histogram_boxplot(data, feature, figsize=(12, 7), kde=False, bins=None):\n",
        "    \"\"\"\n",
        "    Boxplot and histogram combined\n",
        "\n",
        "    data: dataframe\n",
        "    feature: dataframe column\n",
        "    figsize: size of figure (default (12,7))\n",
        "    kde: whether to the show density curve (default False)\n",
        "    bins: number of bins for histogram (default None)\n",
        "    \"\"\"\n",
        "    f2, (ax_box2, ax_hist2) = plt.subplots(\n",
        "        nrows=2,  # Number of rows of the subplot grid= 2\n",
        "        sharex=True,  # x-axis will be shared among all subplots\n",
        "        gridspec_kw={\"height_ratios\": (0.25, 0.75)},\n",
        "        figsize=figsize,\n",
        "    )  # creating the 2 subplots\n",
        "    sns.boxplot(\n",
        "        data=data, x=feature, ax=ax_box2, showmeans=True, color=\"violet\"\n",
        "    )  # boxplot will be created and a star will indicate the mean value of the column\n",
        "    sns.histplot(\n",
        "        data=data, x=feature, kde=kde, ax=ax_hist2, bins=bins, palette=\"winter\"\n",
        "    ) if bins else sns.histplot(\n",
        "        data=data, x=feature, kde=kde, ax=ax_hist2\n",
        "    )  # For histogram\n",
        "    ax_hist2.axvline(\n",
        "        data[feature].mean(), color=\"green\", linestyle=\"--\"\n",
        "    )  # Add mean to the histogram\n",
        "    ax_hist2.axvline(\n",
        "        data[feature].median(), color=\"black\", linestyle=\"-\"\n",
        "    )  # Add median to the histogram"
      ],
      "metadata": {
        "id": "g4dMNNsAqGy3"
      },
      "id": "g4dMNNsAqGy3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Product_Weight"
      ],
      "metadata": {
        "id": "yd23V__rIqAi"
      },
      "id": "yd23V__rIqAi"
    },
    {
      "cell_type": "code",
      "source": [
        "histogram_boxplot(data, \"Product_Weight\")"
      ],
      "metadata": {
        "id": "CKfD_qZ3ImDZ"
      },
      "id": "CKfD_qZ3ImDZ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Product_Allocated_Area"
      ],
      "metadata": {
        "id": "IRE9N4QOIzek"
      },
      "id": "IRE9N4QOIzek"
    },
    {
      "cell_type": "code",
      "source": [
        "histogram_boxplot(data, \"Product_Allocated_Area\")"
      ],
      "metadata": {
        "id": "4o9OLZ2UI76s"
      },
      "id": "4o9OLZ2UI76s",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Product_MRP"
      ],
      "metadata": {
        "id": "UH9173pGJDie"
      },
      "id": "UH9173pGJDie"
    },
    {
      "cell_type": "code",
      "source": [
        "histogram_boxplot(data, \"Product_MRP\")"
      ],
      "metadata": {
        "id": "xf_upHXWJH20"
      },
      "id": "xf_upHXWJH20",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Product_Store_Sales_Total"
      ],
      "metadata": {
        "id": "9iabJrMhIcOw"
      },
      "id": "9iabJrMhIcOw"
    },
    {
      "cell_type": "code",
      "source": [
        "histogram_boxplot(data, \"Product_Store_Sales_Total\")"
      ],
      "metadata": {
        "id": "sG1LS4HeIjCo"
      },
      "id": "sG1LS4HeIjCo",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# function to create labeled barplots\n",
        "\n",
        "\n",
        "def labeled_barplot(data, feature, perc=False, n=None):\n",
        "    \"\"\"\n",
        "    Barplot with percentage at the top\n",
        "\n",
        "    data: dataframe\n",
        "    feature: dataframe column\n",
        "    perc: whether to display percentages instead of count (default is False)\n",
        "    n: displays the top n category levels (default is None, i.e., display all levels)\n",
        "    \"\"\"\n",
        "\n",
        "    total = len(data[feature])  # length of the column\n",
        "    count = data[feature].nunique()\n",
        "    if n is None:\n",
        "        plt.figure(figsize=(count + 1, 5))\n",
        "    else:\n",
        "        plt.figure(figsize=(n + 1, 5))\n",
        "\n",
        "    plt.xticks(rotation=90, fontsize=15)\n",
        "    ax = sns.countplot(\n",
        "        data=data,\n",
        "        x=feature,\n",
        "        palette=\"Paired\",\n",
        "        order=data[feature].value_counts().index[:n].sort_values(),\n",
        "    )\n",
        "\n",
        "    for p in ax.patches:\n",
        "        if perc == True:\n",
        "            label = \"{:.1f}%\".format(\n",
        "                100 * p.get_height() / total\n",
        "            )  # percentage of each class of the category\n",
        "        else:\n",
        "            label = p.get_height()  # count of each level of the category\n",
        "\n",
        "        x = p.get_x() + p.get_width() / 2  # width of the plot\n",
        "        y = p.get_height()  # height of the plot\n",
        "\n",
        "        ax.annotate(\n",
        "            label,\n",
        "            (x, y),\n",
        "            ha=\"center\",\n",
        "            va=\"center\",\n",
        "            size=12,\n",
        "            xytext=(0, 5),\n",
        "            textcoords=\"offset points\",\n",
        "        )  # annotate the percentage\n",
        "\n",
        "    plt.show()  # show the plot"
      ],
      "metadata": {
        "id": "glk94bM0JHqj"
      },
      "id": "glk94bM0JHqj",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Product_Sugar_Content"
      ],
      "metadata": {
        "id": "TIz0ql37JTwQ"
      },
      "id": "TIz0ql37JTwQ"
    },
    {
      "cell_type": "code",
      "source": [
        "labeled_barplot(data, \"Product_Sugar_Content\", perc=True)"
      ],
      "metadata": {
        "id": "Pq06DC9rJb3S"
      },
      "id": "Pq06DC9rJb3S",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Product_Type"
      ],
      "metadata": {
        "id": "TG82cX5bJm_D"
      },
      "id": "TG82cX5bJm_D"
    },
    {
      "cell_type": "code",
      "source": [
        "labeled_barplot(data, \"Product_Type\", perc=True)"
      ],
      "metadata": {
        "id": "LcHAtNJtJr55"
      },
      "id": "LcHAtNJtJr55",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Store_Id"
      ],
      "metadata": {
        "id": "IvFo-eG0J4Yo"
      },
      "id": "IvFo-eG0J4Yo"
    },
    {
      "cell_type": "code",
      "source": [
        "labeled_barplot(data, \"Store_Id\", perc=True)"
      ],
      "metadata": {
        "id": "QTpVLTOQJ9q9"
      },
      "id": "QTpVLTOQJ9q9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Store_Size"
      ],
      "metadata": {
        "id": "HQTS_ywIKBtT"
      },
      "id": "HQTS_ywIKBtT"
    },
    {
      "cell_type": "code",
      "source": [
        "labeled_barplot(data, \"Store_Size\", perc=True)"
      ],
      "metadata": {
        "id": "pC8I4evbKEOQ"
      },
      "id": "pC8I4evbKEOQ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Store_Location_City_Type"
      ],
      "metadata": {
        "id": "xYLY5pu5KJdb"
      },
      "id": "xYLY5pu5KJdb"
    },
    {
      "cell_type": "code",
      "source": [
        "labeled_barplot(data, \"Store_Location_City_Type\", perc=True)"
      ],
      "metadata": {
        "id": "8myt0XRRKSyE"
      },
      "id": "8myt0XRRKSyE",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Store_Type"
      ],
      "metadata": {
        "id": "QpdyLOwMKZCE"
      },
      "id": "QpdyLOwMKZCE"
    },
    {
      "cell_type": "code",
      "source": [
        "labeled_barplot(data, \"Store_Type\", perc=True)"
      ],
      "metadata": {
        "id": "J7HZlQa-Kchj"
      },
      "id": "J7HZlQa-Kchj",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Bivariate Analysis"
      ],
      "metadata": {
        "id": "zk4dmiKGqEmr"
      },
      "id": "zk4dmiKGqEmr"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Correlation Matrix"
      ],
      "metadata": {
        "id": "a_UkA00vKt4T"
      },
      "id": "a_UkA00vKt4T"
    },
    {
      "cell_type": "code",
      "source": [
        "cols_list = data.select_dtypes(include=np.number).columns.tolist()\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "sns.heatmap(\n",
        "    data[cols_list].corr(), annot=True, vmin=-1, vmax=1, fmt=\".2f\", cmap=\"Spectral\"\n",
        ")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "V4I4kXz0qHQf"
      },
      "id": "V4I4kXz0qHQf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Product weight and product MRP correlate well with revenue."
      ],
      "metadata": {
        "id": "BxizRAp-X3b3"
      },
      "id": "BxizRAp-X3b3"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check the distribution of our target variable"
      ],
      "metadata": {
        "id": "4o_yxV-eLB3x"
      },
      "id": "4o_yxV-eLB3x"
    },
    {
      "cell_type": "code",
      "source": [
        "# plot a scatterplot of Product_Weight and Product_Store_Sales_Total\n",
        "plt.figure(figsize=[8, 6])\n",
        "sns.scatterplot(x=data.Product_Weight, y=data.Product_Store_Sales_Total)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "_xHb8k09LgkN"
      },
      "id": "_xHb8k09LgkN",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plot a scatterplot of Product_MRP and Product_Store_Sales_Total\n",
        "plt.figure(figsize=[8, 6])\n",
        "sns.scatterplot(x=data.Product_MRP, y=data.Product_Store_Sales_Total)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Uy3jvMzaLi-a"
      },
      "id": "Uy3jvMzaLi-a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plot a scatterplot of Product_Allocated_Area and Product_Store_Sales_Total\n",
        "plt.figure(figsize=[8, 6])\n",
        "sns.scatterplot(x=data.Product_Allocated_Area, y=data.Product_Store_Sales_Total)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "-xNBQlIKLv4y"
      },
      "id": "-xNBQlIKLv4y",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Product type generating most revenue for the Company"
      ],
      "metadata": {
        "id": "ZaIPRQp4M5ik"
      },
      "id": "ZaIPRQp4M5ik"
    },
    {
      "cell_type": "code",
      "source": [
        "df_revenue1 = data.groupby([\"Product_Type\"], as_index=False)[\n",
        "    \"Product_Store_Sales_Total\"\n",
        "].sum()\n",
        "plt.figure(figsize=[8, 6])\n",
        "plt.xticks(rotation=90)\n",
        "a = sns.barplot(x=df_revenue1.Product_Type, y=df_revenue1.Product_Store_Sales_Total)\n",
        "a.set_xlabel(\"Product_Types\")\n",
        "a.set_ylabel(\"Revenue\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "KAze-22rNBH9"
      },
      "id": "KAze-22rNBH9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform a groupby on Product_Sugar_Content and select Product_Store_Sales_Total\n",
        "df_revenue2 = data.groupby([\"Product_Sugar_Content\"], as_index=False)[\n",
        "    \"Product_Store_Sales_Total\"\n",
        "].sum()\n",
        "plt.figure(figsize=[8, 6])\n",
        "plt.xticks(rotation=90)\n",
        "b = sns.barplot(x=df_revenue2.Product_Sugar_Content, y=df_revenue2.Product_Store_Sales_Total)\n",
        "b.set_xlabel(\"Product_Sugar_Content\")\n",
        "b.set_ylabel(\"Revenue\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "rD19_hZQNNn_"
      },
      "id": "rD19_hZQNNn_",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Find Store types and location generating more revenue for company"
      ],
      "metadata": {
        "id": "mwVOPp8HQpJ7"
      },
      "id": "mwVOPp8HQpJ7"
    },
    {
      "cell_type": "code",
      "source": [
        "df_store_revenue = data.groupby([\"Store_Id\"], as_index=False)[\n",
        "    \"Product_Store_Sales_Total\"\n",
        "].sum()\n",
        "plt.figure(figsize=[8, 6])\n",
        "plt.xticks(rotation=90)\n",
        "r = sns.barplot(x=df_store_revenue.Store_Id, y=df_store_revenue.Product_Store_Sales_Total)\n",
        "r.set_xlabel(\"Stores\")\n",
        "r.set_ylabel(\"Revenue\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "T_7RS_VbQ6BG"
      },
      "id": "T_7RS_VbQ6BG",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform a groupby on Store_Size and select Product_Store_Sales_Total\n",
        "df_revenue3 = data.groupby([\"Store_Size\"], as_index=False)[\n",
        "    \"Product_Store_Sales_Total\"\n",
        "].sum()\n",
        "plt.figure(figsize=[8, 6])\n",
        "plt.xticks(rotation=90)\n",
        "c = sns.barplot(x=df_revenue3.Store_Size, y=df_revenue3.Product_Store_Sales_Total)\n",
        "c.set_xlabel(\"Store_Size\")\n",
        "c.set_ylabel(\"Revenue\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "z6UMPnqXTlVW"
      },
      "id": "z6UMPnqXTlVW",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform a groupby on Store_Location_City and select Product_Store_Sales_Total\n",
        "df_revenue4 = data.groupby([\"Store_Location_City_Type\"], as_index=False)[\n",
        "    \"Product_Store_Sales_Total\"\n",
        "].sum()\n",
        "plt.figure(figsize=[8, 6])\n",
        "plt.xticks(rotation=90)\n",
        "d = sns.barplot(x=df_revenue4.Store_Location_City_Type, y=df_revenue4.Product_Store_Sales_Total)\n",
        "d.set_xlabel(\"Store_Location_City_Type\")\n",
        "d.set_ylabel(\"Revenue\")"
      ],
      "metadata": {
        "id": "9QQIcwhQS5CB"
      },
      "id": "9QQIcwhQS5CB",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform a groupby on Store_type and select Product_Store_Sales_Total\n",
        "df_revenue5 = data.groupby([\"Store_Type\"], as_index=False)[\n",
        "    \"Product_Store_Sales_Total\"\n",
        "].sum()\n",
        "plt.figure(figsize=[8, 6])\n",
        "plt.xticks(rotation=90)\n",
        "e = sns.barplot(x=df_revenue5.Store_Type, y=df_revenue5.Product_Store_Sales_Total)\n",
        "e.set_xlabel(\"Store_Type\")\n",
        "e.set_ylabel(\"Revenue\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "3b1IuiH7TJ_f"
      },
      "id": "3b1IuiH7TJ_f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Checking distribution of target variables"
      ],
      "metadata": {
        "id": "CxTRpO0a1KH2"
      },
      "id": "CxTRpO0a1KH2"
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=[14, 8])\n",
        "sns.boxplot(data=data, x=\"Store_Id\", y=\"Product_Store_Sales_Total\", hue = \"Store_Id\")\n",
        "plt.xticks(rotation=90)\n",
        "plt.title(\"Boxplot - Store_Id Vs Product_Store_Sales_Total\")\n",
        "plt.xlabel(\"Stores\")\n",
        "plt.ylabel(\"Product_Store_Sales_Total (of each product)\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "v_vtGPE41XEr"
      },
      "id": "v_vtGPE41XEr",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=[14, 8])\n",
        "sns.boxplot(data=data, x=\"Store_Size\", y=\"Product_Store_Sales_Total\", hue = \"Store_Size\")\n",
        "plt.xticks(rotation=90)\n",
        "plt.title(\"Boxplot - Store_Size Vs Product_Store_Sales_Total\")\n",
        "plt.xlabel(\"Stores\")\n",
        "plt.ylabel(\"Product_Store_Sales_Total (of each product)\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "loHTFnUZ1j0o"
      },
      "id": "loHTFnUZ1j0o",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Relationships between other columns"
      ],
      "metadata": {
        "id": "-LuKnPDG2H0V"
      },
      "id": "-LuKnPDG2H0V"
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the boxplot with x as Product_Type , y as Product_Weight and hue as Product_Type\n",
        "plt.figure(figsize=[14, 8])\n",
        "sns.boxplot(data = data, x = \"Product_Type\", y = \"Product_Weight\", hue = \"Product_Type\")\n",
        "plt.xticks(rotation=90)\n",
        "plt.title(\"Boxplot - Product_Type Vs Product_Weight\")\n",
        "plt.xlabel(\"Types of Products\")\n",
        "plt.ylabel(\"Product_Weight\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "hysISxKP2NGp"
      },
      "id": "hysISxKP2NGp",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check relationship between weight of product and its sugar content"
      ],
      "metadata": {
        "id": "SGcEUwpT26XU"
      },
      "id": "SGcEUwpT26XU"
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=[14, 8])\n",
        "sns.boxplot(data = data, x = \"Product_Sugar_Content\", y = \"Product_Weight\", hue = \"Product_Sugar_Content\")\n",
        "plt.xticks(rotation=90)\n",
        "plt.title(\"Boxplot - Product_Sugar_Content Vs Product_Weight\")\n",
        "plt.xlabel(\"Product_Sugar_Content\")\n",
        "plt.ylabel(\"Product_Weight\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "098N6_s53GkG"
      },
      "id": "098N6_s53GkG",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Analyzing sugar content of different product types"
      ],
      "metadata": {
        "id": "98JvfQxS3YSU"
      },
      "id": "98JvfQxS3YSU"
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(14, 8))\n",
        "sns.heatmap(\n",
        "    pd.crosstab(data[\"Product_Sugar_Content\"], data[\"Product_Type\"]),\n",
        "    annot=True,\n",
        "    fmt=\"g\",\n",
        "    cmap=\"viridis\",\n",
        ")\n",
        "plt.ylabel(\"Product_Sugar_Content\")\n",
        "plt.xlabel(\"Product_Type\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "eXjFF5wv3gT3"
      },
      "id": "eXjFF5wv3gT3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Low Sugar is dominant across most product types. Fruits and vegetables have the highest number of low sugar items (864), followed by Snack foods (804).\n",
        "\n",
        "- This may indicate a health-conscious product portfolio or consumer preference toward low sugar."
      ],
      "metadata": {
        "id": "KSMZiNvqJN96"
      },
      "id": "KSMZiNvqJN96"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Number of items of each product type sold in each of the stores"
      ],
      "metadata": {
        "id": "reQn-XQT378L"
      },
      "id": "reQn-XQT378L"
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform a crosstab operation between Store_Id and Product_Type\n",
        "plt.figure(figsize=(14, 8))\n",
        "sns.heatmap(\n",
        "    pd.crosstab(data[\"Store_Id\"], data[\"Product_Type\"]),\n",
        "    annot=True,\n",
        "    fmt=\"g\",\n",
        "    cmap=\"viridis\",\n",
        ")\n",
        "plt.ylabel(\"Stores\")\n",
        "plt.xlabel(\"Product_Type\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "qcKHaLEo4EjQ"
      },
      "id": "qcKHaLEo4EjQ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- This heatmap shows store OUT004 dominating in all product categories. My inference from here is that this store is located in a high demand region with a much larger footprint, or could be a central warehouse.\n",
        "- Stores OUT001, OUT002 and OUT003 have a more balanced spread of product types."
      ],
      "metadata": {
        "id": "GcXHbFfqMVZY"
      },
      "id": "GcXHbFfqMVZY"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Analyse trend: Different product types have different prices"
      ],
      "metadata": {
        "id": "GZSUtL3A4k_K"
      },
      "id": "GZSUtL3A4k_K"
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(14, 8))\n",
        "sns.boxplot(data=data, x=\"Product_Type\", y=\"Product_MRP\", hue=\"Product_Type\")\n",
        "plt.xticks(rotation=90)\n",
        "plt.title(\"Boxplot - Product_Type Vs Product_MRP\")\n",
        "plt.xlabel(\"Product_Type\")\n",
        "plt.ylabel(\"Product_MRP (of each product)\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "0QUvGU_J46HX"
      },
      "id": "0QUvGU_J46HX",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Find out how the Product_MRP varies with the different stores"
      ],
      "metadata": {
        "id": "uzCUxx7l5WcO"
      },
      "id": "uzCUxx7l5WcO"
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(14, 8))\n",
        "sns.boxplot(data=data, x=\"Store_Id\", y=\"Product_MRP\", hue=\"Store_Id\")\n",
        "plt.xticks(rotation=90)\n",
        "plt.title(\"Boxplot - Store_Id Vs Product_MRP\")\n",
        "plt.xlabel(\"Stores\")\n",
        "plt.ylabel(\"Product_MRP (of each product)\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "hbmoYfoo5fd_"
      },
      "id": "hbmoYfoo5fd_",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Delve deeper and carry out a detailed analysis of each of the stores"
      ],
      "metadata": {
        "id": "z99kMh2i51GB"
      },
      "id": "z99kMh2i51GB"
    },
    {
      "cell_type": "code",
      "source": [
        "# OUT001\n",
        "data.loc[data[\"Store_Id\"] == \"OUT001\"].describe(include=\"all\").T"
      ],
      "metadata": {
        "id": "uttmZf3f6Aku"
      },
      "id": "uttmZf3f6Aku",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Observations\n",
        "- OUT001 is a store of Supermarket Type 1 which is located in a Tier 2 city and has store size as high. It was established in 1987.\n",
        "- OUT001 has sold products whose MRP range from 71 to 227.\n",
        "- Snack Foods have been sold the highest number of times in OUT001.\n",
        "- The revenue generated from each product at OUT001 ranges from 2300 to 5000.\n",
        "- Low sugar contect products are mostly sold"
      ],
      "metadata": {
        "id": "bC2mcyet6lFL"
      },
      "id": "bC2mcyet6lFL"
    },
    {
      "cell_type": "code",
      "source": [
        "data.loc[data[\"Store_Id\"] == \"OUT001\", \"Product_Store_Sales_Total\"].sum()"
      ],
      "metadata": {
        "id": "Jg--eBbH6nU6"
      },
      "id": "Jg--eBbH6nU6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Store_Id OUT001 generated a total revenue of 6,223,133 from the sale of goods"
      ],
      "metadata": {
        "id": "cFfOamtV7Wma"
      },
      "id": "cFfOamtV7Wma"
    },
    {
      "cell_type": "code",
      "source": [
        "df_OUT001 = (\n",
        "    data.loc[data[\"Store_Id\"] == \"OUT001\"]\n",
        "    .groupby([\"Product_Type\"], as_index=False)[\"Product_Store_Sales_Total\"]\n",
        "    .sum()\n",
        ")\n",
        "plt.figure(figsize=[14, 8])\n",
        "plt.xticks(rotation=90)\n",
        "plt.xlabel(\"Product_Type\")\n",
        "plt.ylabel(\"Product_Store_Sales_Total\")\n",
        "plt.title(\"OUT001\")\n",
        "sns.barplot(x=df_OUT001.Product_Type, y=df_OUT001.Product_Store_Sales_Total)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "daQLglDb7Gfm"
      },
      "id": "daQLglDb7Gfm",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- OUT001 has generated the highest revenue from the sale of fruits and vegetables and snack foods. Both the categories have contributed around 800,000 each."
      ],
      "metadata": {
        "id": "aXHjkZye7Z7N"
      },
      "id": "aXHjkZye7Z7N"
    },
    {
      "cell_type": "code",
      "source": [
        "# OUT002\n",
        "data.loc[data[\"Store_Id\"] == \"OUT002\"].describe(include=\"all\").T"
      ],
      "metadata": {
        "id": "-52uLlK07eX0"
      },
      "id": "-52uLlK07eX0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Observation\n",
        "- OUT002 is a food mart which is located in a Tier 3 city and has store size as small. It was established in 1998.\n",
        "- OUT002 has sold products whose MRP range from 31 to 225.\n",
        "- Fruits and vegetables are the most sold products in OUT002.\n",
        "- The revenue generated from each product at OUT002 ranges from 33 to 2300\n",
        "- Low sugar contect products are mostly sold"
      ],
      "metadata": {
        "id": "lZzDOS2byu2V"
      },
      "id": "lZzDOS2byu2V"
    },
    {
      "cell_type": "code",
      "source": [
        "data.loc[data[\"Store_Id\"] == \"OUT002\", \"Product_Store_Sales_Total\"].sum()"
      ],
      "metadata": {
        "id": "JHpfsC2VzRf6"
      },
      "id": "JHpfsC2VzRf6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Store_Id OUT002 generated a total revenue of 2,030,910 from the sale of goods"
      ],
      "metadata": {
        "id": "J3NU6i77zZcA"
      },
      "id": "J3NU6i77zZcA"
    },
    {
      "cell_type": "code",
      "source": [
        "df_OUT002 = (\n",
        "    data.loc[data[\"Store_Id\"] == \"OUT002\"]\n",
        "    .groupby([\"Product_Type\"], as_index=False)[\"Product_Store_Sales_Total\"]\n",
        "    .sum()\n",
        ")\n",
        "plt.figure(figsize=[14, 8])\n",
        "plt.xticks(rotation=90)\n",
        "plt.xlabel(\"Product_Type\")\n",
        "plt.ylabel(\"Product_Store_Sales_Total\")\n",
        "plt.title(\"OUT002\")\n",
        "sns.barplot(x=df_OUT002.Product_Type, y=df_OUT002.Product_Store_Sales_Total)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "I2no8A64zsBK"
      },
      "id": "I2no8A64zsBK",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- OUT002 has generated the highest revenue from the sale of fruits and vegetables (~ 300,000) followed by snack foods (~ 250,000)."
      ],
      "metadata": {
        "id": "IPtJl18X0LXk"
      },
      "id": "IPtJl18X0LXk"
    },
    {
      "cell_type": "code",
      "source": [
        "# OUT003\n",
        "data.loc[data[\"Store_Id\"] == \"OUT003\"].describe(include=\"all\").T\n"
      ],
      "metadata": {
        "id": "sePgr5q60TcT"
      },
      "id": "sePgr5q60TcT",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Observations\n",
        "- OUT003 is a Departmental store which is located in a Tier 1 city and has store size as medium. It was established in 1999.\n",
        "- OUT003 has sold products whose MRP range from 86 to 266.\n",
        "- Snack Foods are the most sold products in OUT003.\n",
        "- The revenue generated from each product at OUT003 ranges from 3070 to 8000\n",
        "- Low sugar contect products are mostly sold"
      ],
      "metadata": {
        "id": "ZLhxfPRU0ji9"
      },
      "id": "ZLhxfPRU0ji9"
    },
    {
      "cell_type": "code",
      "source": [
        "data.loc[data[\"Store_Id\"] == \"OUT003\", \"Product_Store_Sales_Total\"].sum()"
      ],
      "metadata": {
        "id": "laL4eT1p0nuc"
      },
      "id": "laL4eT1p0nuc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Store_Id OUT003 generated a total revenue of $6,673,457 from the sale of goods"
      ],
      "metadata": {
        "id": "QMeHLMsjOyq8"
      },
      "id": "QMeHLMsjOyq8"
    },
    {
      "cell_type": "code",
      "source": [
        "df_OUT003 = (\n",
        "    data.loc[data[\"Store_Id\"] == \"OUT003\"]\n",
        "    .groupby([\"Product_Type\"], as_index=False)[\"Product_Store_Sales_Total\"]\n",
        "    .sum()\n",
        ")\n",
        "plt.figure(figsize=[14, 8])\n",
        "plt.xticks(rotation=90)\n",
        "plt.xlabel(\"Product_Type\")\n",
        "plt.ylabel(\"Product_Store_Sales_Total\")\n",
        "plt.title(\"OUT003\")\n",
        "sns.barplot(x=df_OUT003.Product_Type, y=df_OUT003.Product_Store_Sales_Total)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "FV4dg50n0zYV"
      },
      "id": "FV4dg50n0zYV",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "OUT003 has generated the highest revenue from the sale of snack foods followed by fruits and vegetables, both contributing over 800,000 each."
      ],
      "metadata": {
        "id": "Pl9vvuUD1jW2"
      },
      "id": "Pl9vvuUD1jW2"
    },
    {
      "cell_type": "code",
      "source": [
        "# OUT004\n",
        "data.loc[data[\"Store_Id\"] == \"OUT004\"].describe(include=\"all\").T"
      ],
      "metadata": {
        "id": "BlHILEiM08mv"
      },
      "id": "BlHILEiM08mv",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- OOUT004 is a store of Supermarket Type2 which is located in a Tier 2 city and has store size as medium. It was established in 2009.\n",
        "- OUT004 has sold products whose MRP range from 83 to 198.\n",
        "- Fruits and vegetables have been sold the highest number of times in OUT004.\n",
        "- The revenue generated from each product at OUT004 ranges from 1561 to 5463.\n",
        "- Low sugar content products are mostly sold."
      ],
      "metadata": {
        "id": "E4fhmXjU1V6o"
      },
      "id": "E4fhmXjU1V6o"
    },
    {
      "cell_type": "code",
      "source": [
        "data.loc[data[\"Store_Id\"] == \"OUT004\", \"Product_Store_Sales_Total\"].sum()"
      ],
      "metadata": {
        "id": "PRV5HD-e1Z8M"
      },
      "id": "PRV5HD-e1Z8M",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Store_Id OUT004 generated a total revenue of 15,427,583 from the sale of goods"
      ],
      "metadata": {
        "id": "HR_bu-HB1fCi"
      },
      "id": "HR_bu-HB1fCi"
    },
    {
      "cell_type": "code",
      "source": [
        "df_OUT004 = (\n",
        "    data.loc[data[\"Store_Id\"] == \"OUT004\"]\n",
        "    .groupby([\"Product_Type\"], as_index=False)[\"Product_Store_Sales_Total\"]\n",
        "    .sum()\n",
        ")\n",
        "plt.figure(figsize=[14, 8])\n",
        "plt.xticks(rotation=90)\n",
        "plt.xlabel(\"Product_Type\")\n",
        "plt.ylabel(\"Product_Store_Sales_Total\")\n",
        "plt.title(\"OUT004\")\n",
        "sns.barplot(x=df_OUT004.Product_Type, y=df_OUT004.Product_Store_Sales_Total)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "WxAHq97u1giX"
      },
      "id": "WxAHq97u1giX",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- OUT004 has generated the highest revenue from the sale of fruits and vegetables (~ 2,500,000) followed by snack foods (~ 2,000,000)."
      ],
      "metadata": {
        "id": "bzArmkty1qFn"
      },
      "id": "bzArmkty1qFn"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Revenue generated by the stores from each of the product types"
      ],
      "metadata": {
        "id": "AudED8mY1wuY"
      },
      "id": "AudED8mY1wuY"
    },
    {
      "cell_type": "code",
      "source": [
        "df1 = data.groupby([\"Product_Type\", \"Store_Id\"], as_index=False)[\n",
        "    \"Product_Store_Sales_Total\"\n",
        "].sum()\n",
        "df1"
      ],
      "metadata": {
        "id": "SwfHSada13Uz"
      },
      "id": "SwfHSada13Uz",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- This is in line with earlier findings with OUT004 genrating more revenue due to sales of more products (~53%).\n",
        "- OUT002 generated the lowest revenue due to being a small store in a Tier 3 city."
      ],
      "metadata": {
        "id": "VOngB0eV16Sr"
      },
      "id": "VOngB0eV16Sr"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Revenue generated by the stores from products having different levels of sugar content.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "3EIHaIwj18tY"
      },
      "id": "3EIHaIwj18tY"
    },
    {
      "cell_type": "code",
      "source": [
        "df2 = data.groupby([\"Product_Sugar_Content\", \"Store_Id\"], as_index=False)[\n",
        "    \"Product_Store_Sales_Total\"\n",
        "].sum()\n",
        "df2"
      ],
      "metadata": {
        "id": "WNMlDm5R2C2W"
      },
      "id": "WNMlDm5R2C2W",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Thsi shows the same trend as before that low sugar content product generated more revenue."
      ],
      "metadata": {
        "id": "2CaVm9Un2Gny"
      },
      "id": "2CaVm9Un2Gny"
    },
    {
      "cell_type": "markdown",
      "id": "0fo5OvIfVdtB",
      "metadata": {
        "id": "0fo5OvIfVdtB"
      },
      "source": [
        "# **Data Preprocessing**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Replacing the values in the Product_Sugar_Content column"
      ],
      "metadata": {
        "id": "22RJ0smIRIcH"
      },
      "id": "22RJ0smIRIcH"
    },
    {
      "cell_type": "code",
      "source": [
        "# Replacing reg with Regular. Looking at the data, these obviously refers to the same category. Spelling was just shortened\n",
        "data.Product_Sugar_Content.replace(to_replace=[\"reg\"], value=[\"Regular\"], inplace=True)"
      ],
      "metadata": {
        "id": "WyqUiOBdqLSN"
      },
      "id": "WyqUiOBdqLSN",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Count the quantity of products in each sugar category\n",
        "data.Product_Sugar_Content.value_counts()"
      ],
      "metadata": {
        "id": "3bX7q4faS5NT"
      },
      "id": "3bX7q4faS5NT",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Exploring Pattern in Product ID"
      ],
      "metadata": {
        "id": "q1sHlSB4TVWg"
      },
      "id": "q1sHlSB4TVWg"
    },
    {
      "cell_type": "code",
      "source": [
        "## extracting the first two characters from the Product_Id column and storing it in another column\n",
        "data[\"Product_Id_char\"] = data[\"Product_Id\"].str[:2]\n",
        "data.head()"
      ],
      "metadata": {
        "id": "TePBFtzdTaVA"
      },
      "id": "TePBFtzdTaVA",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data[\"Product_Id_char\"].unique()"
      ],
      "metadata": {
        "id": "CoUJzDglTkGr"
      },
      "id": "CoUJzDglTkGr",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.loc[data[\"Product_Id_char\"] == \"FD\"]"
      ],
      "metadata": {
        "id": "sFVbt2MITvFt"
      },
      "id": "sFVbt2MITvFt",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.loc[data[\"Product_Id_char\"] == \"DR\"]"
      ],
      "metadata": {
        "id": "MKIDVxVCT8vf"
      },
      "id": "MKIDVxVCT8vf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.loc[data[\"Product_Id_char\"] == \"NC\"]"
      ],
      "metadata": {
        "id": "XD5FN9ndT56m"
      },
      "id": "XD5FN9ndT56m",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Store's Age"
      ],
      "metadata": {
        "id": "qEjmzM7wWLOg"
      },
      "id": "qEjmzM7wWLOg"
    },
    {
      "cell_type": "markdown",
      "source": [
        "The store's age is important and needs to be incorporated into the model because;\n",
        "- An older store is more trustworthy than newer ones\n",
        "- Without proper attention, an older store may lack proper infrastructure, which impacts reveue gereration."
      ],
      "metadata": {
        "id": "YUkRxkN8eUml"
      },
      "id": "YUkRxkN8eUml"
    },
    {
      "cell_type": "code",
      "source": [
        "# Outlet Age\n",
        "data[\"Store_Age_Years\"] = 2025 - data.Store_Establishment_Year"
      ],
      "metadata": {
        "id": "sRpJE18DWOFL"
      },
      "id": "sRpJE18DWOFL",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Group Product Types (total of 16) into 2 broad categories - Perishables and Non- Perishables."
      ],
      "metadata": {
        "id": "6Sx6NFAVWzct"
      },
      "id": "6Sx6NFAVWzct"
    },
    {
      "cell_type": "code",
      "source": [
        "perishables = [\n",
        "    \"Dairy\",\n",
        "    \"Meat\",\n",
        "    \"Fruits and Vegetables\",\n",
        "    \"Breakfast\",\n",
        "    \"Breads\",\n",
        "    \"Seafood\",\n",
        "]"
      ],
      "metadata": {
        "id": "NITfCP8aXP_a"
      },
      "id": "NITfCP8aXP_a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def change(x):\n",
        "    if x in perishables:\n",
        "        return \"Perishables\"\n",
        "    else:\n",
        "        return \"Non Perishables\""
      ],
      "metadata": {
        "id": "UGCXWAuoXgUr"
      },
      "id": "UGCXWAuoXgUr",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['Product_Type_Category'] = data['Product_Type'].apply(change)"
      ],
      "metadata": {
        "id": "UBSoLW2kXuo8"
      },
      "id": "UBSoLW2kXuo8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.head()"
      ],
      "metadata": {
        "id": "ngYme6fWXzBP"
      },
      "id": "ngYme6fWXzBP",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_revenue1 = data.groupby([\"Product_Type_Category\"], as_index=False)[\n",
        "    \"Product_Store_Sales_Total\"\n",
        "].sum()\n",
        "plt.figure(figsize=[8, 6])\n",
        "plt.xticks(rotation=90)\n",
        "a = sns.barplot(x=df_revenue1.Product_Type_Category, y=df_revenue1.Product_Store_Sales_Total)\n",
        "a.set_xlabel(\"Product_Type_category\")\n",
        "a.set_ylabel(\"Revenue\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "hikngoQC8k7Y"
      },
      "id": "hikngoQC8k7Y",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This shows that non perishables generated more revenue than the perishable product types. However the perishables are only 6 product types while the non perishables are 10 product types (resulting in more revenue)"
      ],
      "metadata": {
        "id": "ROydMsaDfgdM"
      },
      "id": "ROydMsaDfgdM"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Outlier Check"
      ],
      "metadata": {
        "id": "IEtsoC5YYHFb"
      },
      "id": "IEtsoC5YYHFb"
    },
    {
      "cell_type": "code",
      "source": [
        "# outlier detection using boxplot\n",
        "numeric_columns = data.select_dtypes(include=np.number).columns.tolist()\n",
        "numeric_columns.remove(\"Store_Establishment_Year\")\n",
        "numeric_columns.remove(\"Store_Age_Years\")\n",
        "\n",
        "\n",
        "plt.figure(figsize=(15, 12))\n",
        "\n",
        "for i, variable in enumerate(numeric_columns):\n",
        "    plt.subplot(4, 4, i + 1)\n",
        "    plt.boxplot(data[variable], whis=1.5)\n",
        "    plt.tight_layout()\n",
        "    plt.title(variable)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Af7jeBNAYO5s"
      },
      "id": "Af7jeBNAYO5s",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- The boxplot shows outliers exists. we already observed that some product types contribute dispropotionately to generated revenue (notably fruits and vegetables, and snacks)"
      ],
      "metadata": {
        "id": "nFJH-zNog3U_"
      },
      "id": "nFJH-zNog3U_"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Preparation for modeling"
      ],
      "metadata": {
        "id": "rzgcspCDYVCu"
      },
      "id": "rzgcspCDYVCu"
    },
    {
      "cell_type": "code",
      "source": [
        "data.head()"
      ],
      "metadata": {
        "id": "7-c8LgifYguT"
      },
      "id": "7-c8LgifYguT",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Remove columns that are not required"
      ],
      "metadata": {
        "id": "AM-wK_2ObF7w"
      },
      "id": "AM-wK_2ObF7w"
    },
    {
      "cell_type": "code",
      "source": [
        "data.drop([\"Product_Id\", \"Product_Type\", \"Store_Establishment_Year\"], axis=1, inplace=True)"
      ],
      "metadata": {
        "id": "FUzpPctTbMJj"
      },
      "id": "FUzpPctTbMJj",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.shape"
      ],
      "metadata": {
        "id": "4Wd1mmj-bjyK"
      },
      "id": "4Wd1mmj-bjyK",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.head()"
      ],
      "metadata": {
        "id": "v-vY-upcboML"
      },
      "id": "v-vY-upcboML",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Separating features and the target column\n",
        "X = data.drop(\"Product_Store_Sales_Total\", axis=1)\n",
        "y = data[\"Product_Store_Sales_Total\"]"
      ],
      "metadata": {
        "id": "Yb4Xzf_-grEY"
      },
      "id": "Yb4Xzf_-grEY",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Splitting the data into train and test sets in 70:30 ratio\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, random_state=1, shuffle=True\n",
        ")"
      ],
      "metadata": {
        "id": "lOzuVtakg1Ht"
      },
      "id": "lOzuVtakg1Ht",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
      ],
      "metadata": {
        "id": "MCClCRt4hHda"
      },
      "id": "MCClCRt4hHda",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Preprocessing Pipeline"
      ],
      "metadata": {
        "id": "s0j2-Em4hSiy"
      },
      "id": "s0j2-Em4hSiy"
    },
    {
      "cell_type": "code",
      "source": [
        "categorical_features = data.select_dtypes(include=['object', 'category']).columns.tolist()\n",
        "categorical_features"
      ],
      "metadata": {
        "id": "29Tb2UAthYH1"
      },
      "id": "29Tb2UAthYH1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a preprocessing pipeline for the categorical features\n",
        "preprocessor = make_column_transformer(\n",
        "    (Pipeline([('encoder', OneHotEncoder(handle_unknown='ignore'))]), categorical_features)\n",
        ")"
      ],
      "metadata": {
        "id": "hvtDota_iQm6"
      },
      "id": "hvtDota_iQm6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "5fd3cabe",
      "metadata": {
        "id": "5fd3cabe"
      },
      "source": [
        "# **Model Building**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As per the project requirement, Only 2 models are to be built."
      ],
      "metadata": {
        "id": "gHpybH6piIuv"
      },
      "id": "gHpybH6piIuv"
    },
    {
      "cell_type": "markdown",
      "id": "YyzOQ8pBY93N",
      "metadata": {
        "id": "YyzOQ8pBY93N"
      },
      "source": [
        "## Define functions for Model Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- We'll fit different models on the train data and observe their performance.\n",
        "- We'll try to improve that performance by tuning some hyperparameters available for that algorithm.\n",
        "- We'll use GridSearchCv for hyperparameter tuning and `r_2 score` to optimize the model.\n",
        "- R-square - `Coefficient of determination` is used to evaluate the performance of a regression model. It is the amount of the variation in the output dependent attribute which is predictable from the input independent variables.\n",
        "- Let's start by creating a function to get model scores, so that we don't have to use the same codes repeatedly."
      ],
      "metadata": {
        "id": "Ld57ckeSh63d"
      },
      "id": "Ld57ckeSh63d"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d107c3d3",
      "metadata": {
        "id": "d107c3d3"
      },
      "outputs": [],
      "source": [
        "# function to compute adjusted R-squared\n",
        "def adj_r2_score(predictors, targets, predictions):\n",
        "    r2 = r2_score(targets, predictions)\n",
        "    n = predictors.shape[0]\n",
        "    k = predictors.shape[1]\n",
        "    return 1 - ((1 - r2) * (n - 1) / (n - k - 1))\n",
        "\n",
        "\n",
        "# function to compute different metrics to check performance of a regression model\n",
        "def model_performance_regression(model, predictors, target):\n",
        "    \"\"\"\n",
        "    Function to compute different metrics to check regression model performance\n",
        "\n",
        "    model: regressor\n",
        "    predictors: independent variables\n",
        "    target: dependent variable\n",
        "    \"\"\"\n",
        "\n",
        "    # predicting using the independent variables\n",
        "    pred = model.predict(predictors)\n",
        "\n",
        "    r2 = r2_score(target, pred)  # to compute R-squared\n",
        "    adjr2 = adj_r2_score(predictors, target, pred)  # to compute adjusted R-squared\n",
        "    rmse = np.sqrt(mean_squared_error(target, pred))  # to compute RMSE\n",
        "    mae = mean_absolute_error(target, pred)  # to compute MAE\n",
        "    mape = mean_absolute_percentage_error(target, pred)  # to compute MAPE\n",
        "\n",
        "    # creating a dataframe of metrics\n",
        "    df_perf = pd.DataFrame(\n",
        "        {\n",
        "            \"RMSE\": rmse,\n",
        "            \"MAE\": mae,\n",
        "            \"R-squared\": r2,\n",
        "            \"Adj. R-squared\": adjr2,\n",
        "            \"MAPE\": mape,\n",
        "        },\n",
        "        index=[0],\n",
        "    )\n",
        "\n",
        "    return df_perf"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The ML models to be built can be any two out of the following:\n",
        "1. Decision Tree\n",
        "2. Bagging\n",
        "3. Random Forest\n",
        "4. AdaBoost\n",
        "5. Gradient Boosting\n",
        "6. XGBoost"
      ],
      "metadata": {
        "id": "P14pbR8nAefF"
      },
      "id": "P14pbR8nAefF"
    },
    {
      "cell_type": "markdown",
      "source": [
        "I chose Random forest and XGBoost models because both handle noise well and manage overfitting better\n",
        "\n"
      ],
      "metadata": {
        "id": "g2IYg7zcnYAH"
      },
      "id": "g2IYg7zcnYAH"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Random Forest Model"
      ],
      "metadata": {
        "id": "LKub0Fn3nb3Q"
      },
      "id": "LKub0Fn3nb3Q"
    },
    {
      "cell_type": "code",
      "source": [
        "# Define random forest regressor\n",
        "\n",
        "rf_estimator = RandomForestRegressor(random_state=1)\n",
        "rf_pipeline = make_pipeline(preprocessor,rf_estimator)\n",
        "rf_pipeline.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "plU8dqWjAd9b"
      },
      "id": "plU8dqWjAd9b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Checking model performance on training set"
      ],
      "metadata": {
        "id": "l7qeur0WtzH2"
      },
      "id": "l7qeur0WtzH2"
    },
    {
      "cell_type": "code",
      "source": [
        "rf_estimator_model_train_perf = model_performance_regression(rf_pipeline, X_train, y_train)\n",
        "rf_estimator_model_train_perf"
      ],
      "metadata": {
        "id": "gITNVJwfuFMl"
      },
      "id": "gITNVJwfuFMl",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Checking model performance on test set"
      ],
      "metadata": {
        "id": "vFJEzsMXuUad"
      },
      "id": "vFJEzsMXuUad"
    },
    {
      "cell_type": "code",
      "source": [
        "rf_estimator_model_test_perf = model_performance_regression(rf_pipeline, X_test, y_test)\n",
        "rf_estimator_model_test_perf"
      ],
      "metadata": {
        "id": "btbreUV3ubE0"
      },
      "id": "btbreUV3ubE0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "XGBoost Regressor"
      ],
      "metadata": {
        "id": "Qv7VUWNeuxO9"
      },
      "id": "Qv7VUWNeuxO9"
    },
    {
      "cell_type": "code",
      "source": [
        "# Define xgboost regressor\n",
        "\n",
        "xgb_estimator = XGBRegressor(random_state=1)\n",
        "xgb_pipeline = make_pipeline(preprocessor,xgb_estimator)\n",
        "xgb_pipeline.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "YLIjxqgeu2nC"
      },
      "id": "YLIjxqgeu2nC",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "checking model performance on training set"
      ],
      "metadata": {
        "id": "1FKsXuwFvM7d"
      },
      "id": "1FKsXuwFvM7d"
    },
    {
      "cell_type": "code",
      "source": [
        "xgb_estimator_model_train_perf = model_performance_regression(xgb_pipeline, X_train, y_train)\n",
        "xgb_estimator_model_train_perf"
      ],
      "metadata": {
        "id": "iZHtlVIfvKY8"
      },
      "id": "iZHtlVIfvKY8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Checking model performance on test set"
      ],
      "metadata": {
        "id": "PZ0UiOb3vbI4"
      },
      "id": "PZ0UiOb3vbI4"
    },
    {
      "cell_type": "code",
      "source": [
        "xgb_estimator_model_test_perf = model_performance_regression(xgb_pipeline, X_test, y_test)\n",
        "xgb_estimator_model_test_perf"
      ],
      "metadata": {
        "id": "NoVXABf8vaSi"
      },
      "id": "NoVXABf8vaSi",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "FtkIDTjdYy5h",
      "metadata": {
        "id": "FtkIDTjdYy5h"
      },
      "source": [
        "# **Model Performance Improvement - Hyperparameter Tuning**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hyperparameter Tuning - Random Forest"
      ],
      "metadata": {
        "id": "DXKe8e-Av7Sl"
      },
      "id": "DXKe8e-Av7Sl"
    },
    {
      "cell_type": "code",
      "source": [
        "# random forest regressor\n",
        "\n",
        "\n",
        "# Choose the type of classifier.\n",
        "rf_tuned = RandomForestRegressor(random_state=1)\n",
        "rf_tuned_pipeline = make_pipeline(preprocessor,rf_tuned)\n",
        "\n",
        "# Grid of parameters to choose from\n",
        "parameters = {\n",
        "\"randomforestregressor__max_depth\": [5, 10, 15, 20, None], #Complete the code to define the list of values to be tuned\n",
        "\"randomforestregressor__max_features\": [\"sqrt\", \"log2\", None], #Complete the code to define the list of values to be tuned\n",
        "\"randomforestregressor__n_estimators\": [100, 200, 300], #Complete the code to define the list of values to be tuned\n",
        "}\n",
        "\n",
        "# Run the grid search\n",
        "grid_obj = GridSearchCV(rf_tuned_pipeline, parameters, scoring=r2_score, cv=3, n_jobs = -1)\n",
        "grid_obj = grid_obj.fit(X_train, y_train)\n",
        "\n",
        "# Set the clf to the best combination of parameters\n",
        "rf_tuned_pipeline = grid_obj.best_estimator_\n",
        "\n",
        "# Fit the best algorithm to the data.\n",
        "rf_tuned_pipeline.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "AFr066WFqVmT"
      },
      "id": "AFr066WFqVmT",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Checking model performance on training set"
      ],
      "metadata": {
        "id": "4I2EE9f2zYyI"
      },
      "id": "4I2EE9f2zYyI"
    },
    {
      "cell_type": "code",
      "source": [
        "rf_tuned_model_train_perf = model_performance_regression(rf_tuned_pipeline, X_train, y_train)\n",
        "rf_tuned_model_train_perf"
      ],
      "metadata": {
        "id": "nmvIyWAY9S57"
      },
      "id": "nmvIyWAY9S57",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Checking model performance on test set"
      ],
      "metadata": {
        "id": "_UbdruH_9ZF0"
      },
      "id": "_UbdruH_9ZF0"
    },
    {
      "cell_type": "code",
      "source": [
        "rf_tuned_model_test_perf = model_performance_regression(rf_tuned_pipeline, X_test, y_test)\n",
        "rf_tuned_model_test_perf"
      ],
      "metadata": {
        "id": "lEjHtlpd9gI4"
      },
      "id": "lEjHtlpd9gI4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hyperparameter Tuning - XGBoost Regressor"
      ],
      "metadata": {
        "id": "rBiCYxQ_-SEI"
      },
      "id": "rBiCYxQ_-SEI"
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the XGBoost Regressor pipeline\n",
        "xgb_tuned = XGBRegressor(random_state=1, objective='reg:squarederror')\n",
        "xgb_tuned_pipeline = make_pipeline(preprocessor, xgb_tuned)\n",
        "\n",
        "# Grid of parameters to choose from\n",
        "parameters = {\n",
        "    \"xgbregressor__n_estimators\": [100, 200, 300],\n",
        "    \"xgbregressor__subsample\": [0.6, 0.8, 1.0],\n",
        "    \"xgbregressor__gamma\": [0, 1, 5],\n",
        "    \"xgbregressor__colsample_bytree\": [0.6, 0.8, 1.0],\n",
        "    \"xgbregressor__colsample_bylevel\": [0.6, 0.8, 1.0]\n",
        "}\n",
        "\n",
        "# Run the grid search with r2 as scoring\n",
        "grid_obj = GridSearchCV(xgb_tuned_pipeline, parameters, scoring='r2', cv=3, n_jobs=-1)\n",
        "grid_obj = grid_obj.fit(X_train, y_train)\n",
        "\n",
        "# Set the model to the best combination of parameters\n",
        "xgb_tuned_pipeline = grid_obj.best_estimator_\n",
        "\n",
        "# Fit the best model to the data\n",
        "xgb_tuned_pipeline.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "uiC0xtQm-e0W"
      },
      "id": "uiC0xtQm-e0W",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Checking the model performance on training set"
      ],
      "metadata": {
        "id": "rRPjg8DG_kyy"
      },
      "id": "rRPjg8DG_kyy"
    },
    {
      "cell_type": "code",
      "source": [
        "xgb_tuned_model_train_perf = model_performance_regression(xgb_tuned_pipeline, X_train, y_train)\n",
        "xgb_tuned_model_train_perf"
      ],
      "metadata": {
        "id": "tLq8yLCP_sMt"
      },
      "id": "tLq8yLCP_sMt",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Checking the model performance on test set"
      ],
      "metadata": {
        "id": "rF5xd8o3_wyB"
      },
      "id": "rF5xd8o3_wyB"
    },
    {
      "cell_type": "code",
      "source": [
        "xgb_tuned_model_test_perf = model_performance_regression(xgb_tuned_pipeline, X_test, y_test)\n",
        "xgb_tuned_model_test_perf"
      ],
      "metadata": {
        "id": "LJfEbMJE_1-o"
      },
      "id": "LJfEbMJE_1-o",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "b0810287",
      "metadata": {
        "id": "b0810287"
      },
      "source": [
        "# **Model Performance Comparison, Final Model Selection, and Serialization**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " # Training performance comparison\n",
        "\n",
        "models_train_comp_df = pd.concat(\n",
        "    [\n",
        "        rf_estimator_model_train_perf.T, #Complete the code to define the variable name of the dataframe which stores the train performance metrics of the first model you have choosen . Eg, rf_model_train_perf\n",
        "        rf_tuned_model_train_perf.T, #Complete the code to define the variable name of the dataframe which stores the train performance metrics of the first model (tuned) you have choosen\n",
        "        xgb_estimator_model_train_perf.T, #Complete the code to define the variable name of the dataframe which stores the train performance metrics of the second model you have choosen\n",
        "        xgb_tuned_model_train_perf.T, #Complete the code to define the variable name of the dataframe which stores the train performance metrics of the second model (tuned) you have choosen\n",
        "    ],\n",
        "    axis=1,\n",
        ")\n",
        "\n",
        "models_train_comp_df.columns = [\"rf_estimator\", \"rf_tuned\", \"xgb_estimator\", \"xgb_tuned\"] #Complete the code to define the names for the models\n",
        "\n",
        "print(\"Training performance comparison:\")\n",
        "models_train_comp_df"
      ],
      "metadata": {
        "id": "X2M3eYFgqZEk"
      },
      "id": "X2M3eYFgqZEk",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " # Test performance comparison\n",
        "\n",
        "models_test_comp_df = pd.concat(\n",
        "    [\n",
        "        rf_estimator_model_test_perf.T, #Complete the code to define the variable name of the dataframe which stores the train performance metrics of the first model you have choosen . Eg, rf_model_train_perf\n",
        "        rf_tuned_model_test_perf.T, #Complete the code to define the variable name of the dataframe which stores the train performance metrics of the first model (tuned) you have choosen\n",
        "        xgb_estimator_model_test_perf.T, #Complete the code to define the variable name of the dataframe which stores the train performance metrics of the second model you have choosen\n",
        "        xgb_tuned_model_test_perf.T, #Complete the code to define the variable name of the dataframe which stores the train performance metrics of the second model (tuned) you have choosen\n",
        "    ],\n",
        "    axis=1,\n",
        ")\n",
        "\n",
        "models_test_comp_df.columns = [\"rf_estimator\", \"rf_tuned\", \"xgb_estimator\", \"xgb_tuned\"] #Complete the code to define the names for the models\n",
        "\n",
        "print(\"Test performance comparison:\")\n",
        "models_test_comp_df"
      ],
      "metadata": {
        "id": "iEqh8adff_mM"
      },
      "id": "iEqh8adff_mM",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a folder for storing the files needed for web app deployment\n",
        "os.makedirs(\"backend_files\", exist_ok=True)"
      ],
      "metadata": {
        "id": "nBtOjdoqh0S1"
      },
      "id": "nBtOjdoqh0S1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the file path to save (serialize) the trained model along with the data preprocessing steps\n",
        "saved_model_path = \"backend_files/revenue_forecast_model.joblib\" #Complete the code to define the name of the model"
      ],
      "metadata": {
        "id": "YMzvGnpJh5FI"
      },
      "id": "YMzvGnpJh5FI",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the best trained model pipeline using joblib\n",
        "joblib.dump(rf_tuned_pipeline, saved_model_path) #Complete the code to pass the variable name of the best model\n",
        "\n",
        "print(f\"Model saved successfully at {saved_model_path}\")"
      ],
      "metadata": {
        "id": "wcawa0xS1dL4"
      },
      "id": "wcawa0xS1dL4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- All the models are very close in performace metrics, but I chose rf_tuned model because it has a slightly better result and it is easier to deploy than the XGBoost.\n",
        "- The XGBoost model typically demands more setuo and tuning than random forest, but in this case with no additonal benefit.  \n",
        "- The tuned models did not show any significant improvement over the baseline models showing they were already well optimized. I would go with it, however as it might see future data that the tuned model might handle better.   "
      ],
      "metadata": {
        "id": "KIeFDsGJ1j9T"
      },
      "id": "KIeFDsGJ1j9T"
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the saved model pipeline from the file\n",
        "saved_model = joblib.load(\"backend_files/revenue_forecast_model.joblib\") #Complete the code to define the name of the saved model\n",
        "\n",
        "# Confirm the model is loaded\n",
        "print(\"Model loaded successfully.\")"
      ],
      "metadata": {
        "id": "0JtfHXo_qJmb"
      },
      "id": "0JtfHXo_qJmb",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "saved_model"
      ],
      "metadata": {
        "id": "m5DpLktT4FSn"
      },
      "id": "m5DpLktT4FSn",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions on the test set using the deserialized model\n",
        "saved_model.predict(X_test)"
      ],
      "metadata": {
        "id": "KQgCrL3J4PcF"
      },
      "id": "KQgCrL3J4PcF",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "9a2LCguV-7i1",
      "metadata": {
        "id": "9a2LCguV-7i1"
      },
      "source": [
        "# **Deployment - Backend**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "T3XlDPUtJnDo",
      "metadata": {
        "id": "T3XlDPUtJnDo"
      },
      "source": [
        "## Flask Web Framework\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking the features saved in model\n",
        "import joblib\n",
        "model = joblib.load(\"backend_files/revenue_forecast_model.joblib\")\n",
        "print(model.feature_names_in_)\n"
      ],
      "metadata": {
        "id": "HbhiKrONOSXo"
      },
      "id": "HbhiKrONOSXo",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Was initially getting a Store_Id not found error in my backend tradeback informaiton, so I included this line of code to confirm all the features were saved prior to deployment."
      ],
      "metadata": {
        "id": "P5X5Q3tjmYYp"
      },
      "id": "P5X5Q3tjmYYp"
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile backend_files/app.py\n",
        "# Import necessary libraries\n",
        "import numpy as np\n",
        "import joblib  # For loading the serialized model\n",
        "import pandas as pd  # For data manipulation\n",
        "from flask import Flask, request, jsonify  # For creating the Flask API\n",
        "import traceback  # For full exception tracebacks\n",
        "\n",
        "# Initialize Flask app\n",
        "superkart_api = Flask(\"SuperKart Sales Api\")\n",
        "\n",
        "# Load the trained sales revenue forecast model\n",
        "model = joblib.load(\"backend_files/revenue_forecast_model.joblib\")\n",
        "print(\"Model loaded. Features expected by the model:\", model.feature_names_in_)\n",
        "\n",
        "# Home route\n",
        "def home():\n",
        "    return \"Welcome to SuperKart Sales Forecasting Api\"\n",
        "\n",
        "@superkart_api.get('/')\n",
        "def home_route():\n",
        "    return home()\n",
        "\n",
        "\n",
        "\n",
        "# Prediction endpoint\n",
        "@superkart_api.post('/v1/predict')\n",
        "def predict_sales():\n",
        "    # 1) Parse JSON payload\n",
        "    data = request.get_json()\n",
        "    print(\"Raw JSON payload:\", data)\n",
        "\n",
        "    # 2) Build the sample dict (keys must match training features)\n",
        "    sample = {\n",
        "        'Product_Weight': data['Product_Weight'],\n",
        "        'Product_Sugar_Content': data['Product_Sugar_Content'],\n",
        "        'Product_Allocated_Area': data['Product_Allocated_Area'],\n",
        "        'Product_MRP': data['Product_MRP'],\n",
        "        'Store_Id': data['Store_Id'],\n",
        "        'Store_Size': data['Store_Size'],\n",
        "        'Store_Location_City_Type': data['Store_Location_City_Type'],\n",
        "        'Store_Type': data['Store_Type'],\n",
        "        'Product_Id_char': data['Product_Id_char'],\n",
        "        'Store_Age_Years': data['Store_Age_Years'],\n",
        "        'Product_Type_Category': data['Product_Type_Category'],\n",
        "    }\n",
        "    print(\"Sample dict keys:\", list(sample.keys()))\n",
        "\n",
        "    # 3) Convert to DataFrame\n",
        "    input_data = pd.DataFrame([sample])\n",
        "    print(\"DataFrame columns before padding:\", input_data.columns.tolist())\n",
        "\n",
        "    # 4) Determine expected columns from model\n",
        "    try:\n",
        "        expected = list(model.feature_names_in_)\n",
        "        print(\"Model expects columns:\", expected)\n",
        "    except Exception:\n",
        "        print(\"Model feature_names_in_ not available; using input columns as fallback\")\n",
        "        expected = input_data.columns.tolist()\n",
        "\n",
        "    # 5) Pad missing columns with None\n",
        "    for col in expected:\n",
        "        if col not in input_data.columns:\n",
        "            input_data[col] = None\n",
        "\n",
        "    # 6) Reorder columns\n",
        "    input_data = input_data[expected]\n",
        "    print(\"DataFrame columns after padding:\", input_data.columns.tolist())\n",
        "    print(\"Input DataFrame preview:\\n\", input_data)\n",
        "\n",
        "    # 7) Predict and handle errors\n",
        "    try:\n",
        "        print(\"About to predict. Input columns:\", input_data.columns.tolist())\n",
        "        prediction = model.predict(input_data).tolist()[0]\n",
        "        print(\"Prediction result:\", prediction)\n",
        "        return jsonify({'Sales': prediction})\n",
        "    except Exception as e:\n",
        "        print(\"Exception during prediction:\\n\", traceback.format_exc())\n",
        "        return jsonify({'error': str(e)}), 500\n",
        "\n",
        "# Run the Flask app in debug mode\n",
        "if __name__ == '__main__':\n",
        "    superkart_api.run(debug=True)\n"
      ],
      "metadata": {
        "id": "29v2IWAg0o6x"
      },
      "id": "29v2IWAg0o6x",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "STDSb04iT-rL",
      "metadata": {
        "id": "STDSb04iT-rL"
      },
      "source": [
        "## Dependencies File"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile backend_files/requirements.txt\n",
        "pandas==2.2.2\n",
        "numpy==2.0.2\n",
        "scikit-learn==1.6.1\n",
        "seaborn==0.13.2\n",
        "joblib==1.4.2\n",
        "xgboost==2.1.4\n",
        "Werkzeug==2.2.2\n",
        "flask==2.2.2\n",
        "gunicorn==20.1.0\n",
        "requests==2.32.3\n",
        "uvicorn[standard]\n",
        "streamlit==1.43.2"
      ],
      "metadata": {
        "id": "tZbPjRESqlf2"
      },
      "id": "tZbPjRESqlf2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "hNFbZBtAJl6l"
      },
      "id": "hNFbZBtAJl6l"
    },
    {
      "cell_type": "markdown",
      "id": "JWD7rPCRUEtD",
      "metadata": {
        "id": "JWD7rPCRUEtD"
      },
      "source": [
        "## Dockerfile"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile backend_files/Dockerfile\n",
        "# Use a minimal base image with Python 3.9 installed\n",
        "FROM python:3.9-slim\n",
        "\n",
        "# Set the working directory inside the container\n",
        "WORKDIR /app\n",
        "\n",
        "# Copy all files from the current directory to the container's working directory\n",
        "COPY . .\n",
        "\n",
        "# Install dependencies from the requirements file without using cache to reduce image size\n",
        "RUN pip install --no-cache-dir --upgrade -r requirements.txt\n",
        "\n",
        "# Define the command to start the application using Gunicorn with 4 worker processes\n",
        "# - `-w 4`: Uses 4 worker processes for handling requests\n",
        "# - `-b 0.0.0.0:7860`: Binds the server to port 7860 on all network interfaces\n",
        "# - `app:superkart_api`: Runs the Flask app (assuming `app.py` contains the Flask instance named `superkart_api`)\n",
        "CMD [\"gunicorn\", \"-w\", \"4\", \"-b\", \"0.0.0.0:7860\", \"app:superkart_api\"]\n"
      ],
      "metadata": {
        "id": "F_IKq5Yp1L4x"
      },
      "id": "F_IKq5Yp1L4x",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "yK1n7jBcRrYr",
      "metadata": {
        "id": "yK1n7jBcRrYr"
      },
      "source": [
        "## Setting up a Hugging Face Docker Space for the Backend"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the login function from the huggingface_hub library\n",
        "from huggingface_hub import login\n",
        "\n",
        "# Login to your Hugging Face account using your access token\n",
        "# Replace \"YOUR_HUGGINGFACE_TOKEN\" with your actual token\n",
        "#login(token=\"YOUR_HUGGINGFACE_TOKEN\")  # You can get your token from https://huggingface.co/settings/tokens\n",
        "login(token=\"hf_token\") #Complete the code to define the access token\n",
        "\n",
        "# Import the create_repo function from the huggingface_hub library\n",
        "from huggingface_hub import create_repo"
      ],
      "metadata": {
        "id": "IYOJipQ3qmrD"
      },
      "id": "IYOJipQ3qmrD",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Try to create the repository for the Hugging Face Space\n",
        "try:\n",
        "    create_repo(\"superkart-sales-forecast\",  # Define the name of the repository\n",
        "        repo_type=\"space\",  # Specify the repository type as \"space\"\n",
        "        space_sdk=\"docker\",  # Specify the space SDK as \"docker\"\n",
        "        private=False  # Set to True if you want the space to be private\n",
        "    )\n",
        "except Exception as e:\n",
        "    # Handle potential errors during repository creation\n",
        "    if \"RepositoryAlreadyExistsError\" in str(e):\n",
        "        print(\"Repository already exists. Skipping creation.\")\n",
        "    else:\n",
        "        print(f\"Error creating repository: {e}\")"
      ],
      "metadata": {
        "id": "6Axb3Dl4kpj-"
      },
      "id": "6Axb3Dl4kpj-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "B4tnVrlo8xQ9",
      "metadata": {
        "id": "B4tnVrlo8xQ9"
      },
      "source": [
        "## Uploading Files to Hugging Face Space (Docker Space)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# for hugging face space authentication to upload files\n",
        "from huggingface_hub import HfApi, upload_folder\n",
        "\n",
        "access_key = \"hf_token\"  #Complete the code to define the access token\n",
        "repo_id = \"sesekheigbe/Superkart-Sales-Forecast\"  #Complete the code to define the repo id.\n",
        "\n",
        "# Login to Hugging Face platform with the access token\n",
        "login(token=access_key)\n",
        "\n",
        "# Initialize the API\n",
        "api = HfApi()\n",
        "\n",
        "# Upload Streamlit app files stored in the folder called backend_files\n",
        "api.upload_folder(\n",
        "    folder_path=\"backend_files\",\n",
        "    path_in_repo=\"\",\n",
        "    repo_id=repo_id,  # Hugging face space id\n",
        "    repo_type=\"space\",  # Hugging face repo type \"space\"\n",
        ")"
      ],
      "metadata": {
        "id": "naObvoxDqnMS"
      },
      "id": "naObvoxDqnMS",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "bv07DWg0_G6L",
      "metadata": {
        "id": "bv07DWg0_G6L"
      },
      "source": [
        "# **Deployment - Frontend**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Points to note before executing the below cells\n",
        "- Create a Streamlit space on Hugging Face by following the instructions provided on the content page titled **`Creating Spaces and Adding Secrets in Hugging Face`** from Week 1"
      ],
      "metadata": {
        "id": "3J1woYZNGhXh"
      },
      "id": "3J1woYZNGhXh"
    },
    {
      "cell_type": "markdown",
      "id": "UsCYxkq_UL3Q",
      "metadata": {
        "id": "UsCYxkq_UL3Q"
      },
      "source": [
        "## Streamlit for Interactive UI"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a folder for storing the files needed for frontend UI deployment\n",
        "os.makedirs(\"frontend_files\", exist_ok=True)"
      ],
      "metadata": {
        "id": "aC_Py-S9qpsJ"
      },
      "id": "aC_Py-S9qpsJ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile frontend_files/app.py\n",
        "\n",
        "import streamlit as st\n",
        "import requests\n",
        "\n",
        "# Title of the app\n",
        "st.title(\"SuperKart Sales Forecasting Tool\")\n",
        "\n",
        "# Input fields for product and store data\n",
        "Product_Weight = st.number_input(\"Product Weight (in kg)\", min_value=0.0, value=12.66)\n",
        "\n",
        "Product_Sugar_Content = st.selectbox(\n",
        "    \"Product Sugar Content\",\n",
        "    [\"Low Sugar\", \"Regular\", \"No Sugar\"]\n",
        ")\n",
        "\n",
        "Product_Allocated_Area = st.number_input(\n",
        "    \"Product Allocated Area (sq ft)\", min_value=0.0, value=0.07\n",
        ")\n",
        "\n",
        "Product_MRP = st.number_input(\n",
        "    \"Product MRP (₹)\", min_value=0.0, value=150.0\n",
        ")\n",
        "\n",
        "Store_Id = st.selectbox(\n",
        "    \"Store Id\", [\"OUT001\", \"OUT002\", \"OUT003\", \"OUT004\"]\n",
        ")\n",
        "\n",
        "Store_Size = st.selectbox(\n",
        "    \"Store Size\",\n",
        "    [\"Small\", \"Medium\", \"High\"]\n",
        ")\n",
        "\n",
        "Store_Location_City_Type = st.selectbox(\n",
        "    \"Store Location City Type\",\n",
        "    [\"Tier 1\", \"Tier 2\", \"Tier 3\"]\n",
        ")\n",
        "\n",
        "Store_Type = st.selectbox(\n",
        "    \"Store Type\",\n",
        "    [\"Department Store\", \"Food Mart\", \"Supermarket Type 1\", \"Supermarket Type 2\"]\n",
        ")\n",
        "\n",
        "Product_Id_char = st.text_input(\n",
        "    \"Product ID Prefix (e.g., FDW, DRN, NC)\",\n",
        "    value=\"FDW\"\n",
        ")\n",
        "\n",
        "Store_Age_Years = st.number_input(\n",
        "    \"Store Age (in years)\", min_value=0, value=23\n",
        ")\n",
        "\n",
        "Product_Type_Category = st.selectbox(\n",
        "    \"Product Type Category\",\n",
        "     [\"Perishables\", \"Non Perishables\"]\n",
        ")\n",
        "\n",
        "\n",
        "# Prepare the data dictionary\n",
        "product_data = {\n",
        "    \"Product_Weight\": Product_Weight,\n",
        "    \"Product_Sugar_Content\": Product_Sugar_Content,\n",
        "    \"Product_Allocated_Area\": Product_Allocated_Area,\n",
        "    \"Product_MRP\": Product_MRP,\n",
        "    \"Store_Id\": Store_Id,\n",
        "    \"Store_Size\": Store_Size,\n",
        "    \"Store_Location_City_Type\": Store_Location_City_Type,\n",
        "    \"Store_Type\": Store_Type,\n",
        "    \"Product_Id_char\": Product_Id_char,\n",
        "    \"Store_Age_Years\": Store_Age_Years,\n",
        "    \"Product_Type_Category\": Product_Type_Category\n",
        "}\n",
        "\n",
        "# DEBUG: Show the request payload before submitting\n",
        "st.subheader(\"🧾 Request JSON Preview\")\n",
        "st.json(product_data)\n",
        "\n",
        "# Button to trigger prediction\n",
        "if st.button(\"Predict\", type='primary'):\n",
        "    # Replace <user_name> and <space_name> with your actual Hugging Face values\n",
        "    response = requests.post(\n",
        "        \"https://sesekheigbe-superkart-sales-forecast.hf.space/v1/predict\",\n",
        "        json=product_data\n",
        "    )\n",
        "\n",
        "\n",
        "    if response.status_code == 200:\n",
        "        result = response.json()\n",
        "        predicted_sales = result[\"Sales\"]\n",
        "        st.success(f\"Predicted Product Store Sales Total: ₹{predicted_sales:.2f}\")\n",
        "    else:\n",
        "        st.error(\"Error in API request\")\n"
      ],
      "metadata": {
        "id": "YOcEJ-GUANZV"
      },
      "execution_count": null,
      "outputs": [],
      "id": "YOcEJ-GUANZV"
    },
    {
      "cell_type": "markdown",
      "id": "beq1RbMhUQmi",
      "metadata": {
        "id": "beq1RbMhUQmi"
      },
      "source": [
        "## Dependencies File"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile frontend_files/requirements.txt\n",
        "requests==2.32.3\n",
        "streamlit==1.45.0"
      ],
      "metadata": {
        "id": "3BcfxQ1VGjb6"
      },
      "id": "3BcfxQ1VGjb6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "B-zE77eWcuGo",
      "metadata": {
        "id": "B-zE77eWcuGo"
      },
      "source": [
        "## DockerFile"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile frontend_files/Dockerfile\n",
        "# Use a minimal base image with Python 3.9 installed\n",
        "FROM python:3.9-slim\n",
        "\n",
        "# Set the working directory inside the container to /app\n",
        "WORKDIR /app\n",
        "\n",
        "# Copy all files from the current directory on the host to the container's /app directory\n",
        "COPY . .\n",
        "\n",
        "# Create Streamlit config with correct Hugging Face port (7860)\n",
        "RUN mkdir -p /app/.streamlit && \\\n",
        "    echo \"\\\n",
        "[server]\\n\\\n",
        "port = 8501\\n\\\n",
        "enableCORS = false\\n\\\n",
        "enableXsrfProtection = false\\n\\\n",
        "headless = true\\n\\\n",
        "\\n\\\n",
        "[browser]\\n\\\n",
        "gatherUsageStats = false\\n\\\n",
        "\" > /app/.streamlit/config.toml\n",
        "\n",
        "\n",
        "# Install Python dependencies listed in requirements.txt\n",
        "RUN pip3 install -r requirements.txt\n",
        "\n",
        "# Define the command to run the Streamlit app on port 8501 and make it accessible externally\n",
        "CMD [\"streamlit\", \"run\", \"app.py\", \"--server.port=8501\", \"--server.address=0.0.0.0\", \"--server.enableXsrfProtection=false\"]\n",
        "\n",
        "# NOTE: Disable XSRF protection for easier external access in order to make batch predictions"
      ],
      "metadata": {
        "id": "Tl5MzECZGufV"
      },
      "id": "Tl5MzECZGufV",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "5Re8ovwv9Rb5",
      "metadata": {
        "id": "5Re8ovwv9Rb5"
      },
      "source": [
        "## Uploading Files to Hugging Face Space (Streamlit Space)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "access_key = \"hf_token\"  #Complete the code to define the access token\n",
        "repo_id = \"sesekheigbe/superkartforecast-ui\"  #Complete the code to define the repo id\n",
        "\n",
        "# Login to Hugging Face platform with the access token\n",
        "login(token=access_key)\n",
        "\n",
        "# Initialize the API\n",
        "api = HfApi()\n",
        "\n",
        "# Upload Streamlit app files stored in the folder called frontend_files\n",
        "api.upload_folder(\n",
        "    folder_path=\"frontend_files\",\n",
        "    repo_id=repo_id,  # Hugging face space id\n",
        "    repo_type=\"space\",  # Hugging face repo type \"space\"\n",
        ")"
      ],
      "metadata": {
        "id": "GKFHV8c0qs-l"
      },
      "id": "GKFHV8c0qs-l",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Backend link:   https://huggingface.co/spaces/sesekheigbe/superkart-sales-forecast?logs=container\n",
        "\n",
        "Frontend link: https://huggingface.co/spaces/sesekheigbe/superkartforecast-ui"
      ],
      "metadata": {
        "id": "dTWK_7faW47k"
      },
      "id": "dTWK_7faW47k"
    },
    {
      "cell_type": "markdown",
      "id": "e4213339",
      "metadata": {
        "id": "e4213339"
      },
      "source": [
        "# **Actionable Insights and Business Recommendations**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Actionable Insights:\n",
        "\n",
        "1. Non-Perishable items (e.g. Frozen Foods, Snacks, Canned Foods) collectively generate significantly more revenue than Perishables. However on an product basis, fruits and vegetables (perishable), and snacks (non-perishable) are the biggest contributors to revenue generation.\n",
        "\n",
        "2. Larger store sizes (especially 'Medium'), Store type (Supermarket Type 2) and location city (Tier 2) seem to have positive effects on revenue. This also happens to fit the OUT004 description. OUT004 has 3 to 4 times more product counts than each of the individaul stores. This can skew the data in favor od these fetures. OUT004 seems to me like a distrubtion or wholesale center.\n",
        "\n",
        "3. Product MRP and weight Influence Sales numbers. Products with higher MRP and larger weights correlate positively with revenue, highlighting the importance of premium pricing, which is also influenced by the product weight.\n",
        "\n",
        "4. Low Sugar is dominant across most product types, contributing to more revenue. Fruits and vegetables have the highest number of low sugar items (864), followed by Snack foods (804). This may indicate a health-conscious product portfolio or consumer preference toward low sugar.\n",
        "\n",
        "5. The RF and XGBoost models gave results with similar confidence level (r-squared @ 0.668 and adjusted r-squared @ 0.667. MAPE @ 0.187). However the RF was chosen because XGBoost typically demands more setup and tuning than random forest, but in this case with no additonal benefit.\n",
        "\n",
        "\n",
        "Business Recommendations\n",
        "\n",
        "1. Prioritize Expansion of high demand perishables like Fresh Fruits and vegetables,and Non-Perishables products like Snacks, Frozen Foods, and Canned Goods. Strengthen marketing, promotions, and shelf space allocation for such high-performing items.\n",
        "\n",
        "2. Store OUT004, from the data provided outpaced all other stores in product sales. This store should be studied and some best prctices for increased revenue applied in the running of other stores.\n",
        "\n",
        "3. Optimize Store Layout and Size.\n",
        "Invest in expanding or redesigning smaller stores toward medium/large formats to maximize revenue potential.\n",
        "\n",
        "4. Stores like OUT003 which is already rightly size and has high MAR can have their revenue optimized by redistributing the product selection to shelf more of the high performing products. This can help enhance overall revenue.\n",
        "\n",
        "5. Implement an inventory control strategy that will ensure that fast moving products are restocked timely. Take advantage of the health conscious communities, ensuring low sugar items continue to dominate the shelfs.\n",
        "\n",
        "6. Continue to gather data, comparing the model's forecast with the actual revenue. This will help in fine tuning the model. if required for better forecast reliabiltiy."
      ],
      "metadata": {
        "id": "4rqiZdIh5kOM"
      },
      "id": "4rqiZdIh5kOM"
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}